{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW3IW_vqBOVr"
   },
   "source": [
    "# Text Generation with Hugging Face Transformers\n",
    "\n",
    "*This script demonstrates how to use Hugging Face\n",
    "Transformers to perform text generation\n",
    "using a pre-trained GPT model. The model is hosted on Hugging Face's platform, and the\n",
    "Hugging Face Hub API is used for authentication and model loading.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxsZiTJnAe46",
    "outputId": "683c3bff-e552-4473-efca-e4a448b81b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install transformers torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwKn9HmaB6Y1"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DsfOPFKLCAKp"
   },
   "outputs": [],
   "source": [
    "# Retrieve the Hugging Face API token securely from Colab's user data\n",
    "my_secret = userdata.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZ-pjU0nCZFu"
   },
   "outputs": [],
   "source": [
    "# Log in to Hugging Face Hub\n",
    "hf_token = my_secret  # Ensure this is securely stored or retrieved\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agJbxUmRCbty"
   },
   "outputs": [],
   "source": [
    "# Define the model ID\n",
    "model_id = \"gpt2\"  # Change to other GPT models if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0qmFRdwCrAN",
    "outputId": "f59e1ad0-8c9a-4e97-cb77-9ebddd8b6ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model...\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "print(\"Loading tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xX3BIPQfDp27"
   },
   "outputs": [],
   "source": [
    "# Optional: Set the pad token if required\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GhSKT5w8Gk3X"
   },
   "outputs": [],
   "source": [
    "# Set up the text generation pipeline\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=200,  # Set the number of tokens to generate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vt5BjihMGqT7",
    "outputId": "1906598c-2a01-4085-83e1-0867d37f333c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text...\n",
      "Generated text:\n",
      "[{'generated_text': 'Explain about AI.\\n\\n\"You\\'d think AI would be a very simple thing to implement. No one wants to spend ten hours with a human working on that issue. That might change. A lot of this is a lot more technical than what you\\'d have with humans. But we\\'re working on it anyway.\\n\\n\"If you\\'ve seen any of our work on AI in our development, you\\'ll know that sometimes the idea of AI is very appealing. There is always a tension with some of it. Most of my work doesn\\'t use real languages, and I find it very hard to deal with the question of just the amount of effort that people put into an AI.\\n\\n\"For me, AI would be better spent talking with my AI team and making sure it is well understood. Also, with the new AI system being able to interact with objects from outside its range of vision, I may want to push beyond what some other systems are currently designed to do.\\n\\n\"When you have'}]\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "print(\"Generating text...\")\n",
    "prompt = \"Explain about AI.\"\n",
    "output = text_generator(prompt)\n",
    "\n",
    "# Print the generated output\n",
    "print(\"Generated text:\")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
